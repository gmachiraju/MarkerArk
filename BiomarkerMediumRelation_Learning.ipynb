{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import BiomarkerMediumRelation_Extraction\n",
    "\n",
    "\n",
    "import cPickle, os, sys, matplotlib\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from snorkel.snorkel import *\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (18,6)\n",
    "filename = \"text/AGR2_blood_biomarker.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Relations = BiomarkerDiseaseRelation_Extraction.generateRelations(_filename= filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTE: Relations.pkl is probably wrong file for this learning file\n",
    "feats = None\n",
    "relationsFile = \"cache/\" + filename + \"/relations.pkl\"\n",
    "if not os.path.exists(\"cache/\" + filename +\"/\" ):\n",
    "    os.makedirs(\"cache/\" + filename + \"/\")\n",
    "try:\n",
    "    with open(relationsFile, 'rb') as f:\n",
    "        feats = cPickle.load(f)\n",
    "except:\n",
    "    %time Relations.extract_features()\n",
    "    with open(relationsFile, 'w+') as f:\n",
    "        cPickle.dump(Relations.feats, f)\n",
    "\n",
    "DDL = DDLiteModel(Relations, feats)\n",
    "print \"Extracted {} features for each of {} mentions\".format(DDL.num_feats(), DDL.num_candidates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuples = []\n",
    "list = re.split(\"[^\\\\S ]\", open(\"tags6.tsv\").read())\n",
    "count = 7\n",
    "while count < len(list):\n",
    "    number = 0\n",
    "    if (list[count + 6] == \"true\"):\n",
    "        number = 1\n",
    "    elif (list[count + 6] == \"false\"):\n",
    "        number = -1\n",
    "    tuples.append((list[count + 5] + \"::\" + list[count + 3] + \"::[\" + list[count + 4] + \", \" + list[count] + \"]::['\" +\n",
    "                 list[count + 1] + \"', '\" + list[count + 2] + \"']\", number))\n",
    "    count += 7\n",
    "gt = []\n",
    "uids = []\n",
    "for tuple in tuples:\n",
    "    uids.append(tuple[0])\n",
    "    gt.append(tuple[1])\n",
    "\n",
    "\n",
    "# with open('examples/gene_tag_example/gt/uids.pkl', 'rb') as f:\n",
    "#     uids2 = cPickle.load(f)\n",
    "# with open('examples/gene_tag_example/gt/gt.pkl', 'rb') as f:\n",
    "#     gt2 = cPickle.load(f)\n",
    "    \n",
    "DDL.update_gt(gt = gt[:50], uids = uids[:50])\n",
    "DDL.set_holdout(validation_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.open_mindtagger(num_sample=200, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.add_mindtagger_tags()\n",
    "DDL.update_gt(gt=gt[50:], uids=uids[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_keyword_lemmas = [\"contain\", \"collect\", \"find\", \"sample\", \"fluid\", \"tissue\", \"detection\"]\n",
    "sentences = []\n",
    "# 1- distance far\n",
    "def LF_distance_far(m):\n",
    "    # print m.lemmas\n",
    "    # print m.dep_labels\n",
    "    distance = abs(m.e2_idxs[0] - m.e1_idxs[0])\n",
    "    if distance < 10:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "        \n",
    "            \n",
    "# 2- distance close\n",
    "def LF_distance_close(m):\n",
    "    # print m.lemmas\n",
    "    # print m.dep_labels\n",
    "    distance = abs(m.e2_idxs[0] - m.e1_idxs[0])\n",
    "    if distance < 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 3-  Biomarker + preposition + Medium\n",
    "def LF_IN(m):\n",
    "    return 1 if (('IN' in m.post_window1('poses', 5) and 'IN' in m.pre_window2('poses',5))) or (('IN' in m.post_window2('poses', 5) and 'IN' in m.pre_window1('poses',5))) else 0 \n",
    "         \n",
    "# 4- If the sentence contains common keywords\n",
    "def LF_keyword(m):\n",
    "    for word in sentence_keyword_lemmas:\n",
    "        if (word in m.pre_window1('lemmas',20)) or (word in m.post_window1('lemmas',20)):\n",
    "            #if presenceOfNot(m):\n",
    "            #    return -1\n",
    "            #else:\n",
    "            #    return 1\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# 5- Medium \"from\" patients or subjects\n",
    "def LF_From(m):\n",
    "    index = 0\n",
    "    post = m.post_window2('lemmas',20)\n",
    "    if 'patient' in post:\n",
    "        index = post.index('patient')\n",
    "    elif 'subject' in post:\n",
    "        index = post.index('subject')\n",
    "    return 1 if \"from\" in m.post_window2('lemmas',index) else 0\n",
    "\n",
    "# 6- Medium \"-based\": blood-based biomarker\n",
    "def LF_based(m):\n",
    "    mediumBased = m.mention2(attribute='words') + \"-based\"\n",
    "    return 1 if mediumBased in m.pre_window1('words',20) or mediumBased in m.post_window1('words',20) else 0\n",
    "\n",
    "# 7- Medium \"biomarker\": blood biomarker\n",
    "def LF_biomarker(m):\n",
    "    return 1 if 'biomarker' in m.post_window2('lemmas',3) else 0\n",
    "\n",
    "# 8- if that relationship is in the references, MIGHT NOT WORK\n",
    "def LF_References(m):\n",
    "    sent_id = m.post_window1('sent_id',1)\n",
    "    sentences_before = sentences[0:sent_id]\n",
    "    for sentence in sentences_before:\n",
    "        if 'References' in sentence.words():\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = []\n",
    "DDL.apply_lfs(LFs, clear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.lowest_empirical_accuracy_lfs(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "mu_seq = np.ravel([1e-9, 1e-5, 1e-3, 1e-1])\n",
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'sample': False, 'n_iter': 3000, 'alpha': 0.5, 'mu': mu_seq, 'bias': False, 'verbose': True}\n",
    "%time DDL.train_model(method='lr', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DDL.plot_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "acc_lfs = np.mean(DDL.get_lf_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"LF accuracy: {:.3f}\\nFull model accuracy: {:.3f}\".format(acc_lfs, acc_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}